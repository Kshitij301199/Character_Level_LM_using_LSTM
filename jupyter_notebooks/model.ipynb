{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size: int, hidden_size: int, num_layers: int, num_classes: int):\n",
    "        \"\"\"\n",
    "        Think about which (hyper-)parameters your model needs; \n",
    "        i.e., parameters that determine the\n",
    "        exact shape (as opposed to the architecture) of the model.\n",
    "        There's an embedding layer, which needs to know how many elements it needs to embed,\n",
    "        and into vectors of what size.\n",
    "        There's a recurrent layer, which needs to know the size of its input (coming from\n",
    "        the embedding layer).\n",
    "        PyTorch also makes it easy to create a stack of such layers in one command;\n",
    "        the size of the stack can be given here. Finally, the output of the recurrent layer(s) \n",
    "        needs to be projected again into a vector of a specified size.\n",
    "        \"\"\"\n",
    "        super(LSTM,self).__init__()\n",
    "        \n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        \n",
    "        self.num_classes = num_classes\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first = True)\n",
    "        self.output_layer = nn.Linear(hidden_size, num_classes)\n",
    "        # self.relu = nn.ReLU()\n",
    "\n",
    "        # self.init_hidden()\n",
    "        \n",
    "    def forward(self, x, hidden, cell):\n",
    "        output = self.embedding(x)\n",
    "        output, (hidden, cell) = self.lstm(output.unsqueeze(1), (hidden, cell))\n",
    "        output = self.output_layer(output.reshape(output.shape[0], -1))\n",
    "        return output, (hidden, cell)\n",
    "\n",
    "\n",
    "    def init_hidden(self, batch_size=1):\n",
    "        if batch_size == 1:\n",
    "            hidden = torch.zeros(self.num_layers, self.hidden_size)\n",
    "            cell = torch.zeros(self.num_layers, self.hidden_size)\n",
    "        else:\n",
    "            hidden = torch.zeros(self.num_layers, batch_size, self.hidden_size)\n",
    "            cell = torch.zeros(self.num_layers,  batch_size, self.hidden_size)    \n",
    "        return hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unidecode\n",
    "import string\n",
    "import random\n",
    "\n",
    "CHUNK_LEN = 200\n",
    "TRAIN_PATH = '../data/dickens_train.txt'\n",
    "\n",
    "def load_dataset(path):\n",
    "    all_characters = string.printable\n",
    "    n_characters = len(all_characters)\n",
    "\n",
    "    file = unidecode.unidecode(open(path, 'r').read())\n",
    "    return file\n",
    "\n",
    "def random_chunk():\n",
    "    file = load_dataset(TRAIN_PATH)\n",
    "    start_index = random.randint(0, len(file) - CHUNK_LEN - 1)\n",
    "    end_index = start_index + CHUNK_LEN + 1\n",
    "    return file[start_index:end_index]\n",
    "\n",
    "def char_tensor(strings):\n",
    "    all_characters = string.printable\n",
    "    tensor = torch.zeros(len(strings)).long()\n",
    "    for index,char in enumerate(strings):\n",
    "        tensor[index] = all_characters.index(char)\n",
    "    return Variable(tensor)\n",
    "\n",
    "def random_training_set():\n",
    "    chunk = random_chunk()\n",
    "    inp = char_tensor(chunk[:-1])\n",
    "    target = char_tensor(chunk[1:])\n",
    "    return inp, target\n",
    "\n",
    "def time_since(since):\n",
    "    \"\"\"\n",
    "    A helper to print the amount of time passed.\n",
    "    \"\"\"\n",
    "    s = time.time() - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(decoder, prime_str='A', predict_len=100, temperature=0.8):\n",
    "    hidden, cell = decoder.init_hidden()\n",
    "    prime_input = char_tensor(prime_str)\n",
    "    predicted = prime_str\n",
    "    all_characters = string.printable\n",
    "\n",
    "    # Use priming string to \"build up\" hidden state\n",
    "    for p in range(len(prime_str) - 1):\n",
    "        _, (hidden, cell) = decoder(prime_input[p], (hidden, cell)) \n",
    "    inp = prime_input[-1]\n",
    "\n",
    "    for p in range(predict_len):\n",
    "        output, (hidden, cell) = decoder(inp, (hidden, cell))\n",
    "\n",
    "        # Sample from the network as a multinomial distribution\n",
    "        output_dist = output.data.view(-1).div(temperature).exp()\n",
    "        top_i = torch.multinomial(output_dist, 1)[0]\n",
    "\n",
    "        # Add predicted character to string and use as next input\n",
    "        predicted_char = all_characters[top_i]\n",
    "        predicted += predicted_char\n",
    "        inp = char_tensor(predicted_char)\n",
    "\n",
    "    return predicted\n",
    "\n",
    "\n",
    "def train(decoder, decoder_optimizer, inp, target):\n",
    "    hidden, cell = decoder.init_hidden()\n",
    "    decoder.zero_grad()\n",
    "    loss = 0\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    for c in range(CHUNK_LEN):\n",
    "        output, (hidden, cell) = decoder(inp[c], hidden, cell)\n",
    "        loss += criterion(output, target[c].view(1))\n",
    "\n",
    "    loss.backward()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / CHUNK_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "input.size(-1) must be equal to input_size. Expected 100, got 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [26]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m loss_avg \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, n_epochs\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m---> 19\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrandom_training_set\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m     loss_avg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m print_every \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "Input \u001b[1;32mIn [25]\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(decoder, decoder_optimizer, inp, target)\u001b[0m\n\u001b[0;32m     31\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(CHUNK_LEN):\n\u001b[1;32m---> 34\u001b[0m     output, (hidden, cell) \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43minp\u001b[49m\u001b[43m[\u001b[49m\u001b[43mc\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcell\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m     loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m criterion(output, target[c]\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     37\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\kshit\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\kshit\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Input \u001b[1;32mIn [23]\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, x, hidden, cell)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, hidden, cell):\n\u001b[0;32m     32\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding(x)\n\u001b[1;32m---> 33\u001b[0m     output, (hidden, cell) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcell\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_layer(output\u001b[38;5;241m.\u001b[39mreshape(output\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output, (hidden, cell)\n",
      "File \u001b[1;32mc:\\Users\\kshit\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\kshit\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kshit\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:875\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    872\u001b[0m             hx \u001b[38;5;241m=\u001b[39m (hx[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m), hx[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m    873\u001b[0m         \u001b[38;5;66;03m# Each batch of the hidden state should match the input sequence that\u001b[39;00m\n\u001b[0;32m    874\u001b[0m         \u001b[38;5;66;03m# the user believes he/she is passing in.\u001b[39;00m\n\u001b[1;32m--> 875\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_forward_args\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    876\u001b[0m         hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[0;32m    878\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\kshit\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:790\u001b[0m, in \u001b[0;36mLSTM.check_forward_args\u001b[1;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[0;32m    785\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_forward_args\u001b[39m(\u001b[38;5;28mself\u001b[39m,  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[0;32m    786\u001b[0m                        \u001b[38;5;28minput\u001b[39m: Tensor,\n\u001b[0;32m    787\u001b[0m                        hidden: Tuple[Tensor, Tensor],\n\u001b[0;32m    788\u001b[0m                        batch_sizes: Optional[Tensor],\n\u001b[0;32m    789\u001b[0m                        ):\n\u001b[1;32m--> 790\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    791\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_hidden_size(hidden[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_expected_hidden_size(\u001b[38;5;28minput\u001b[39m, batch_sizes),\n\u001b[0;32m    792\u001b[0m                            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected hidden[0] size \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    793\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_hidden_size(hidden[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_expected_cell_size(\u001b[38;5;28minput\u001b[39m, batch_sizes),\n\u001b[0;32m    794\u001b[0m                            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected hidden[1] size \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\kshit\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:236\u001b[0m, in \u001b[0;36mRNNBase.check_input\u001b[1;34m(self, input, batch_sizes)\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    234\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput must have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_input_dim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m dimensions, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_size \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m--> 236\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    237\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput.size(-1) must be equal to input_size. Expected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: input.size(-1) must be equal to input_size. Expected 100, got 1"
     ]
    }
   ],
   "source": [
    "all_characters = string.printable\n",
    "n_characters = len(all_characters)\n",
    "\n",
    "n_epochs = 3000\n",
    "print_every = 100\n",
    "plot_every = 10\n",
    "hidden_size = 128\n",
    "n_layers = 2\n",
    "\n",
    "lr = 0.005\n",
    "decoder = LSTM(n_characters, hidden_size, n_characters, n_layers)\n",
    "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=lr)\n",
    "\n",
    "start = time.time()\n",
    "all_losses = []\n",
    "loss_avg = 0\n",
    "\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    loss = train(decoder, decoder_optimizer, *random_training_set())\n",
    "    loss_avg += loss\n",
    "\n",
    "    if epoch % print_every == 0:\n",
    "        print('[{} ({} {}%) {:.4f}]'.format(time_since(start), epoch, epoch/n_epochs * 100, loss))\n",
    "        print(generate(decoder, 'A', 100), '\\n')\n",
    "\n",
    "    if epoch % plot_every == 0:\n",
    "        all_losses.append(loss_avg / plot_every)\n",
    "        loss_avg = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_characters = string.printable\n",
    "n_characters = len(all_characters)\n",
    "\n",
    "n_epochs = 3000\n",
    "print_every = 100\n",
    "plot_every = 10\n",
    "hidden_size = 128\n",
    "n_layers = 2\n",
    "\n",
    "lr = 0.005\n",
    "decoder = LSTM(n_characters, hidden_size, n_layers, n_characters)\n",
    "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM(\n",
      "  (embedding): Embedding(100, 128)\n",
      "  (lstm): LSTM(100, 128, num_layers=2, batch_first=True)\n",
      "  (output_layer): Linear(in_features=128, out_features=100, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.005\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(decoder_optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden, cell = decoder.init_hidden()\n",
    "decoder.zero_grad()\n",
    "loss = 0\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 128])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 128])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp, target = random_training_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "input.size(-1) must be equal to input_size. Expected 100, got 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [173]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43minp\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcell\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kshit\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\kshit\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Input \u001b[1;32mIn [162]\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, x, hidden, cell)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, hidden, cell):\n\u001b[0;32m     32\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding(x)\n\u001b[1;32m---> 33\u001b[0m     output, (hidden, cell) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcell\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_layer(output\u001b[38;5;241m.\u001b[39mreshape(output\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output, (hidden, cell)\n",
      "File \u001b[1;32mc:\\Users\\kshit\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\kshit\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kshit\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:875\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    872\u001b[0m             hx \u001b[38;5;241m=\u001b[39m (hx[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m), hx[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m    873\u001b[0m         \u001b[38;5;66;03m# Each batch of the hidden state should match the input sequence that\u001b[39;00m\n\u001b[0;32m    874\u001b[0m         \u001b[38;5;66;03m# the user believes he/she is passing in.\u001b[39;00m\n\u001b[1;32m--> 875\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_forward_args\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    876\u001b[0m         hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[0;32m    878\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\kshit\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:790\u001b[0m, in \u001b[0;36mLSTM.check_forward_args\u001b[1;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[0;32m    785\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_forward_args\u001b[39m(\u001b[38;5;28mself\u001b[39m,  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[0;32m    786\u001b[0m                        \u001b[38;5;28minput\u001b[39m: Tensor,\n\u001b[0;32m    787\u001b[0m                        hidden: Tuple[Tensor, Tensor],\n\u001b[0;32m    788\u001b[0m                        batch_sizes: Optional[Tensor],\n\u001b[0;32m    789\u001b[0m                        ):\n\u001b[1;32m--> 790\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    791\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_hidden_size(hidden[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_expected_hidden_size(\u001b[38;5;28minput\u001b[39m, batch_sizes),\n\u001b[0;32m    792\u001b[0m                            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected hidden[0] size \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    793\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_hidden_size(hidden[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_expected_cell_size(\u001b[38;5;28minput\u001b[39m, batch_sizes),\n\u001b[0;32m    794\u001b[0m                            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected hidden[1] size \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\kshit\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:236\u001b[0m, in \u001b[0;36mRNNBase.check_input\u001b[1;34m(self, input, batch_sizes)\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    234\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput must have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_input_dim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m dimensions, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_size \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m--> 236\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    237\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput.size(-1) must be equal to input_size. Expected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: input.size(-1) must be equal to input_size. Expected 100, got 1"
     ]
    }
   ],
   "source": [
    "decoder(inp[0],hidden,cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.zeros(100).long()\n",
    "t[inp[0]] = 1.\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = decoder.embedding(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 128])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = nn.LSTM(n_characters, hidden_size, 2, batch_first = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "input.size(-1) must be equal to input_size. Expected 100, got 128",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [195]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43memb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcell\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kshit\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\kshit\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kshit\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:875\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    872\u001b[0m             hx \u001b[38;5;241m=\u001b[39m (hx[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m), hx[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m    873\u001b[0m         \u001b[38;5;66;03m# Each batch of the hidden state should match the input sequence that\u001b[39;00m\n\u001b[0;32m    874\u001b[0m         \u001b[38;5;66;03m# the user believes he/she is passing in.\u001b[39;00m\n\u001b[1;32m--> 875\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_forward_args\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    876\u001b[0m         hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[0;32m    878\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\kshit\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:790\u001b[0m, in \u001b[0;36mLSTM.check_forward_args\u001b[1;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[0;32m    785\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_forward_args\u001b[39m(\u001b[38;5;28mself\u001b[39m,  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[0;32m    786\u001b[0m                        \u001b[38;5;28minput\u001b[39m: Tensor,\n\u001b[0;32m    787\u001b[0m                        hidden: Tuple[Tensor, Tensor],\n\u001b[0;32m    788\u001b[0m                        batch_sizes: Optional[Tensor],\n\u001b[0;32m    789\u001b[0m                        ):\n\u001b[1;32m--> 790\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    791\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_hidden_size(hidden[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_expected_hidden_size(\u001b[38;5;28minput\u001b[39m, batch_sizes),\n\u001b[0;32m    792\u001b[0m                            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected hidden[0] size \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    793\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_hidden_size(hidden[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_expected_cell_size(\u001b[38;5;28minput\u001b[39m, batch_sizes),\n\u001b[0;32m    794\u001b[0m                            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected hidden[1] size \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\kshit\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:236\u001b[0m, in \u001b[0;36mRNNBase.check_input\u001b[1;34m(self, input, batch_sizes)\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    234\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput must have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_input_dim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m dimensions, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_size \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m--> 236\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    237\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput.size(-1) must be equal to input_size. Expected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: input.size(-1) must be equal to input_size. Expected 100, got 128"
     ]
    }
   ],
   "source": [
    "lstm(emb,(hidden,cell))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparam_list = [\n",
    "            {\"n_epochs\" : 3000, \"hidden_size\" : 128, \"n_layers\" : 2, \"lr\" : 0.005, \"opt\" : \"Adam\"},\n",
    "            {\"n_epochs\" : 3500, \"hidden_size\" : 128, \"n_layers\" : 2, \"lr\" : 0.005, \"opt\" : \"Adam\"},\n",
    "            {\"n_epochs\" : 4000, \"hidden_size\" : 128, \"n_layers\" : 2, \"lr\" : 0.005, \"opt\" : \"Adam\"},\n",
    "            {\"n_epochs\" : 4500, \"hidden_size\" : 128, \"n_layers\" : 2, \"lr\" : 0.005, \"opt\" : \"Adam\"}, # tune n_epochs\n",
    "            {\"n_epochs\" : 3000, \"hidden_size\" : 32, \"n_layers\" : 2, \"lr\" : 0.005, \"opt\" : \"Adam\"},\n",
    "            {\"n_epochs\" : 3000, \"hidden_size\" : 64, \"n_layers\" : 2, \"lr\" : 0.005, \"opt\" : \"Adam\"},\n",
    "            \n",
    "            {\"n_epochs\" : 3000, \"hidden_size\" : 256, \"n_layers\" : 2, \"lr\" : 0.005, \"opt\" : \"Adam\"}, # tune hidden_size\n",
    "            {\"n_epochs\" : 3000, \"hidden_size\" : 128, \"n_layers\" : 1, \"lr\" : 0.005, \"opt\" : \"Adam\"},\n",
    "            \n",
    "            {\"n_epochs\" : 3000, \"hidden_size\" : 128, \"n_layers\" : 3, \"lr\" : 0.005, \"opt\" : \"Adam\"},\n",
    "            {\"n_epochs\" : 3000, \"hidden_size\" : 128, \"n_layers\" : 4, \"lr\" : 0.005, \"opt\" : \"Adam\"}, # tune n_layers\n",
    "            \n",
    "            {\"n_epochs\" : 3000, \"hidden_size\" : 128, \"n_layers\" : 2, \"lr\" : 0.01, \"opt\" : \"Adam\"},\n",
    "            {\"n_epochs\" : 3000, \"hidden_size\" : 128, \"n_layers\" : 2, \"lr\" : 0.015, \"opt\" : \"Adam\"},\n",
    "            {\"n_epochs\" : 3000, \"hidden_size\" : 128, \"n_layers\" : 2, \"lr\" : 0.02, \"opt\" : \"Adam\"}, # tune lr\n",
    "            \n",
    "            {\"n_epochs\" : 3000, \"hidden_size\" : 128, \"n_layers\" : 2, \"lr\" : 0.005, \"opt\" : \"AdamW\"},\n",
    "            {\"n_epochs\" : 3000, \"hidden_size\" : 128, \"n_layers\" : 2, \"lr\" : 0.005, \"opt\" : \"RMSprop\"} # tune opt\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000 100 10 128 2 0.005 A 100 0.8 Adam\n",
      "3500 100 10 128 2 0.005 A 100 0.8 Adam\n",
      "4000 100 10 128 2 0.005 A 100 0.8 Adam\n",
      "4500 100 10 128 2 0.005 A 100 0.8 Adam\n",
      "3000 100 10 32 2 0.005 A 100 0.8 Adam\n",
      "3000 100 10 64 2 0.005 A 100 0.8 Adam\n",
      "3000 100 10 256 2 0.005 A 100 0.8 Adam\n",
      "3000 100 10 128 1 0.005 A 100 0.8 Adam\n",
      "3000 100 10 128 3 0.005 A 100 0.8 Adam\n",
      "3000 100 10 128 4 0.005 A 100 0.8 Adam\n",
      "3000 100 10 128 2 0.01 A 100 0.8 Adam\n",
      "3000 100 10 128 2 0.015 A 100 0.8 Adam\n",
      "3000 100 10 128 2 0.02 A 100 0.8 Adam\n",
      "3000 100 10 128 2 0.005 A 100 0.8 AdamW\n",
      "3000 100 10 128 2 0.005 A 100 0.8 RMSprop\n"
     ]
    }
   ],
   "source": [
    "for hyperparams in hyperparam_list:\n",
    "    tuner(**hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_inputs(n_epochs, hidden_size, n_layers,lr,opt):\n",
    "    print(n_epochs, hidden_size, n_layers,lr,opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuner(n_epochs : int = 3000,\n",
    "          print_every : int = 100,\n",
    "          plot_every  : int = 10,\n",
    "          hidden_size : int = 128,\n",
    "          n_layers : int = 2,\n",
    "          lr :float = 0.005,\n",
    "          start_string : str = 'A',\n",
    "          prediction_length : int = 100,\n",
    "          temperature : float = 0.8,\n",
    "          opt : str = \"Adam\"):\n",
    "    print(n_epochs,print_every,plot_every,hidden_size,n_layers,lr,start_string,prediction_length,temperature,opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_colours = [\"red\",\"blue\",\"green\",\"yellow\",\"purple\",\"black\",\"violet\",\"grey\",\"cyan\",\"magenta\"]\n",
    "colours = random.sample(all_colours,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_list = [0.1,0.05,0.01,0.005,0.001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1cbbfa80eb0>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.style.use('seaborn')\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.xticks(fontweight='bold', size=12)\n",
    "plt.yticks(fontweight='bold', size=12)\n",
    "plt.tick_params(axis='both', direction='in')\n",
    "all_colours = [\"red\",\"blue\",\"green\",\"yellow\",\"purple\",\"black\",\"violet\",\"grey\",\"cyan\",\"magenta\"]\n",
    "colours = random.sample(all_colours,len(lr_list))\n",
    "x = np.arange(0,3000,10)\n",
    "for index,lr in enumerate(lr_list):\n",
    "    plt.plot(x,[lr]*300,colours[index],label = f\"{lr}\")\n",
    "    \n",
    "plt.xlabel(\"Number of iterations\",fontsize=15,fontweight='bold')\n",
    "plt.ylabel(\"CrossEntropy Loss\",fontsize=15,fontweight='bold')\n",
    "plt.legend(prop = {\"size\":12,\"weight\":\"bold\"},loc='best',labelcolor='linecolor',\n",
    "           frameon = True, fancybox = True,framealpha=1,\n",
    "           facecolor = \"white\", edgecolor=\"black\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values =  [2.4994462558563946,2.4225304126160276,2.945138813506362,2.6649904551517634,2.3927558140149703,2.503693651509312,2.605775321127309, 2.7594953814404346, 2.54451165817949, 2.664610644079394, 2.6922874844239466, 2.5109406691908243, 2.366963940213506]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~ \\t\\n\\r\\x0b\\x0c'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "all_characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Sample data with headers\n",
    "data = [\n",
    "    {'Name': 'John', 'Age': 25, 'City': 'New York'},\n",
    "    {'Name': 'Alice', 'Age': 30, 'City': 'San Francisco'},\n",
    "    {'Name': 'Bob', 'Age': 22, 'City': 'Los Angeles'}\n",
    "]\n",
    "\n",
    "new = {\"Work\" : [\"A\",\"B\",\"C\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data with headers written to 'test.txt'\n"
     ]
    }
   ],
   "source": [
    "# Specify the file name\n",
    "file_name = 'test.txt'\n",
    "\n",
    "# Write data with headers to the file\n",
    "with open(file_name, 'w', newline='') as file:\n",
    "    # Extract headers from the first dictionary\n",
    "    headers = list(data[0].keys())\n",
    "\n",
    "    # Create a CSV writer\n",
    "    writer = csv.DictWriter(file, fieldnames=headers,delimiter=\"\\t\")\n",
    "\n",
    "    # Write headers to the file\n",
    "    writer.writeheader()\n",
    "    \n",
    "    writer.writerows(data)\n",
    "    \n",
    "\n",
    "print(f\"Data with headers written to '{file_name}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparam_list = [\n",
    "            {\"n_epochs\" : 2000, \"hidden_size\" : 128, \"n_layers\" : 2, \"lr\" : 0.005, \"opt\" : \"Adam\"},\n",
    "            {\"n_epochs\" : 4000, \"hidden_size\" : 128, \"n_layers\" : 2, \"lr\" : 0.005, \"opt\" : \"Adam\"}, # tune n_epochs\n",
    "            {\"n_epochs\" : 2000, \"hidden_size\" : 64, \"n_layers\" : 2, \"lr\" : 0.005, \"opt\" : \"Adam\"},\n",
    "            {\"n_epochs\" : 2000, \"hidden_size\" : 256, \"n_layers\" : 2, \"lr\" : 0.005, \"opt\" : \"Adam\"}, # tune hidden_size\n",
    "            {\"n_epochs\" : 2000, \"hidden_size\" : 128, \"n_layers\" : 1, \"lr\" : 0.005, \"opt\" : \"Adam\"},\n",
    "            {\"n_epochs\" : 2000, \"hidden_size\" : 128, \"n_layers\" : 3, \"lr\" : 0.005, \"opt\" : \"Adam\"}, # tune n_layers\n",
    "            {\"n_epochs\" : 2000, \"hidden_size\" : 128, \"n_layers\" : 2, \"lr\" : 0.1, \"opt\" : \"Adam\"},\n",
    "            {\"n_epochs\" : 2000, \"hidden_size\" : 128, \"n_layers\" : 2, \"lr\" : 0.01, \"opt\" : \"Adam\"},\n",
    "            {\"n_epochs\" : 2000, \"hidden_size\" : 128, \"n_layers\" : 2, \"lr\" : 0.001, \"opt\" : \"Adam\"}, # tune lr\n",
    "            {\"n_epochs\" : 2000, \"hidden_size\" : 128, \"n_layers\" : 2, \"lr\" : 0.005, \"opt\" : \"AdamW\"},\n",
    "            {\"n_epochs\" : 2000, \"hidden_size\" : 128, \"n_layers\" : 2, \"lr\" : 0.005, \"opt\" : \"RMSprop\"}, # tune opt\n",
    "            {\"n_epochs\" : 2000, \"hidden_size\" : 256, \"n_layers\" : 2, \"lr\" : 0.005, \"opt\" : \"RMSprop\"}\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "values =  [2.4994462558563946,2.4225304126160276,2.945138813506362,2.6649904551517634,2.3927558140149703,2.503693651509312,2.605775321127309, 2.7594953814404346, 2.54451165817949, 2.664610644079394, 2.6922874844239466, 2.5109406691908243]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hyperparam_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'test.txt'\n",
    "with open(file_name, 'w', newline='') as file:\n",
    "    headers = list(hyperparam_list[0].keys())\n",
    "    headers.append(\"BPC\")\n",
    "\n",
    "    writer = csv.DictWriter(file, fieldnames = headers, delimiter=\"\\t\")\n",
    "\n",
    "    writer.writeheader()\n",
    "    for hyperparams, value in zip(hyperparam_list,values):\n",
    "        # print(f\"{keys} Configuration {hyperparams}\\n BPC = {values}\")\n",
    "        writer.writerow(hyperparams | {\"BPC\" : value})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['n_epochs', 'hidden_size', 'n_layers', 'lr', 'opt', 'BPC']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers.append(\"BPC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['n_epochs', 'hidden_size', 'n_layers', 'lr', 'opt', 'BPC']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
